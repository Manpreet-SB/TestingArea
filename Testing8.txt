import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score


# Sample dataset
data = {
    "id": [1, 2, 3, 4, 5, 6, 7],
    "age": [25, 34, 45, 23, 35, 40, 29],  # Numerical column
    "income": [50000, 60000, 80000, 45000, 70000, 75000, 52000],  # Numerical column
    "gender": ["Male", "Female", "Male", "Female", "Male", "Female", "Male"],  # Categorical column
    "city": ["New York", "Los Angeles", "Chicago", "Houston", "Phoenix", "Chicago", "Houston"],  # Categorical column
    "feedback": [  # Textual column
        "Great product, will buy again.",
        "Had issues with delivery, but customer service was helpful.",
        "Satisfied with the quality.",
        "Product arrived late and damaged.",
        "Exceptional service and fast delivery.",
        "Terrible experience, will not recommend.",
        "Fast delivery but average quality."
    ],
    "sentiment": ["positive", "neutral", "positive", None, "positive", "negative", "neutral"],  # Target column with NaN
}

df = pd.DataFrame(data)

# Drop rows with missing target values (NaN)
df = df.dropna(subset=["sentiment"])

# Frequency encoding for categorical columns
categorical_columns = ["gender", "city"]
for col in categorical_columns:
    freq = df[col].value_counts(normalize=True)  # Compute frequencies
    df[col] = df[col].map(freq)  # Replace values with their frequencies

# Separate the unique ID and target column
ids = df["id"]
target = df["sentiment"]

# Define features and binary target (positive=1, not positive=0)
features = df.drop(columns=["id", "sentiment"])
labels = target.map({"positive": 1, "neutral": 0, "negative": 0})  # Binary classification

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42, stratify=labels)

# Define column types
numerical_columns = ["age", "income"]
text_column = "feedback"

# Preprocessing steps
# 1. Standard scaling for numerical columns
numerical_transformer = StandardScaler()

# 2. TF-IDF vectorization for textual data
text_transformer = TfidfVectorizer(max_features=10)  # Limit features for simplicity

# Combine all preprocessing steps into a column transformer
preprocessor = ColumnTransformer(
    transformers=[
        ("num", numerical_transformer, numerical_columns),
        ("text", text_transformer, text_column),
    ],
    remainder="passthrough",  # Pass through frequency-encoded categorical columns
)

# Classification pipeline
model = Pipeline(
    steps=[
        ("preprocessor", preprocessor),
        ("classifier", RandomForestClassifier(random_state=42, n_estimators=100)),  # Random Forest Classifier
    ]
)

# Train the model
model.fit(X_train, y_train)

# Evaluate accuracy on the train and test set
train_preds = model.predict(X_train)
test_preds = model.predict(X_test)

train_accuracy = accuracy_score(y_train, train_preds)
test_accuracy = accuracy_score(y_test, test_preds)

print(f"Train Accuracy: {train_accuracy:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# Print classification report
print("\nClassification Report (Test Data):")
print(classification_report(y_test, test_preds, target_names=["not positive", "positive"]))

# Combine processed features with predictions for the test set (optional)
# Dynamically generate column names for processed data
num_features = numerical_columns
text_features = preprocessor.named_transformers_["text"].get_feature_names_out()
categorical_features = categorical_columns

processed_columns = list(num_features) + list(text_features) + list(categorical_features)

X_test_processed = pd.DataFrame(
    model.named_steps["preprocessor"].transform(X_test),
    columns=processed_columns,
    index=X_test.index,
)
X_test_processed["id"] = X_test.index.values
X_test_processed["true_sentiment"] = y_test.values
X_test_processed["predicted_sentiment"] = test_preds

print("\nProcessed Features with Predictions:")
print(X_test_processed.head())
